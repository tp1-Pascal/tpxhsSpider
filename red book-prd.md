

## 给 Opus 的 PRD 提示词

```
# 项目：小红书多关键词自动抓取测试（Phase 4）

## 目标
验证完整的自动化流程：从读取关键词文件到输出结构化数据，全程无需人工干预。

## 测试规模
- 关键词数量：10 个（从 md 文件读取）
- 每个关键词抓取：5 条（点赞最高）
- 总计：50 条内容

## 前置条件
- 用户已在浏览器中登录小红书网页版
- 用户已准备好 keywords.md 文件

## 输入文件

### keywords.md 格式
```markdown
# 抓取关键词列表

- 失眠
- 焦虑
- 冥想
- 睡眠质量
- 助眠
- 褪黑素
- 深度睡眠
- 早起
- 作息
- 情绪管理
```

或者简单格式（每行一个）：
```markdown
失眠
焦虑
冥想
睡眠质量
助眠
褪黑素
深度睡眠
早起
作息
情绪管理
```

两种格式都要支持解析。

## 输出结构

### 文件夹结构
output/
├── data.json                 # 所有数据汇总
├── progress.json             # 进度记录
└── images/                   # 封面图片
├── 失眠_001.jpg
├── 失眠_002.jpg
├── 焦虑_001.jpg
└── ...

### data.json 结构
```json
[
  {
    "keyword": "失眠",
    "rank": 1,
    "url": "https://www.xiaohongshu.com/explore/xxxxx",
    "title": "笔记标题",
    "content": "笔记正文全文...",
    "likes": 12345,
    "collects": 6789,
    "comments": 234,
    "author": "作者昵称",
    "cover_image": "images/失眠_001.jpg",
    "scraped_at": "2025-01-25T16:00:00Z"
  }
]
```

## 执行流程

### 启动命令
用户发送："开始测试" 或 "启动抓取"

### 步骤 1：读取关键词
- 读取 keywords.md
- 解析出关键词列表
- 显示确认信息：
📋 已读取 10 个关键词：

失眠
焦虑
冥想
...

每个关键词抓取 5 条（点赞最高）
总计：50 条
发送"确认"开始执行

### 步骤 2：循环处理每个关键词

对于每个关键词，执行以下操作：

**2.1 搜索关键词**
- 导航到小红书首页或搜索页
- 找到搜索框，清空已有内容
- 模拟人类打字速度输入关键词（每字符 100-200ms）
- 按 Enter 或点击搜索按钮
- 等待搜索结果加载（2-3 秒）

**2.2 选择排序与时间筛选（严谨版）**
- 点击"筛选"按钮展开菜单
- **必须选中**：排序依据 -> "最多点赞"
- **必须选中**：发布时间 -> "一周内"
- 观察筛选状态，确保菜单显示为“已筛选”且对应项高亮
- 等待结果重新排序并应用筛选（3-5 秒）

**2.3 抓取前 5 条**
- 从排序后的列表中，提取前 5 条笔记的链接
- 对每条笔记：
  1. 使用 window.open 打开详情页
  2. 等待页面加载（2-3 秒）
  3. 提取内容：标题、正文、点赞、收藏、评论、作者
  4. 提取封面图（首图或视频封面）：
     - 找到详情页的主图/视频封面
     - 获取图片 URL
     - 下载图片保存到 images/ 文件夹
     - 命名格式：[关键词]_[序号].jpg
  5. **关闭详情页标签**：内容抓取完成后，必须立即关闭该标签页，严防内存溢出。
  6. 随机等待 3-6 秒

**2.4 记录进度**
- 更新 progress.json
- 显示当前进度：
✅ 完成：失眠 (5/5)
📊 总进度：1/10 关键词
⏳ 下一个：焦虑

**2.5 关键词间休息**
- 随机等待 20-40 秒
- 然后处理下一个关键词

### 步骤 3：完成汇报
🎉 测试完成！
📊 统计

关键词：10 个
抓取内容：48 条（2 条失败）
下载图片：48 张

📁 输出位置

数据：output/data.json
图片：output/images/


## 封面图抓取要求

### 图片类型判断
- 如果是图文笔记：抓取第一张图
- 如果是视频笔记：抓取视频封面图

### 下载逻辑
1. 获取图片的完整 URL
2. 下载图片二进制数据
3. 保存到 output/images/ 目录
4. 文件名：[关键词]_[序号].[扩展名]
5. 如果下载失败，记录错误但继续执行

### 图片 URL 处理
- 小红书图片 URL 可能带有参数和签名
- 尝试获取最高清晰度的版本
- 如果有 webp 格式，优先使用（或转换为 jpg）

## 防检测策略

### 时间控制
- 打字速度：每字符 100-200ms
- 搜索后等待：2-3 秒
- 切换排序后等待：2-3 秒
- 打开详情页后等待：2-3 秒
- 抓取完一条后等待：3-6 秒
- 关键词之间等待：20-40 秒

### 行为随机化
- 所有等待时间加入 ±30% 随机浮动
- 点击位置加入 ±5px 随机偏移
- 偶尔在页面上随机移动鼠标

## 断点续传
- progress.json 记录已完成的关键词
- 如果中断后重新启动，自动跳过已完成的
- 显示："检测到上次进度，已完成 3/10，是否继续？"

## 验收标准
1. 能正确解析 keywords.md（支持两种格式）
2. 能自动在搜索框输入关键词
3. 能自动选择"最热"排序
4. 能抓取每个关键词的前 5 条内容
5. 能下载并保存封面图片
6. 10 个关键词全部处理完成
7. data.json 包含完整数据
8. images/ 文件夹包含对应图片

## 测试用的 keywords.md 内容
你可以用以下内容创建测试文件：
```markdown
失眠
焦虑
冥想
睡眠质量
助眠
褪黑素
深度睡眠
早起
作息
情绪管理
```

## 注意事项
- 这是测试阶段，规模较小（10×5=50 条）
- 如果全部成功，后续可以扩展到 20-50 个关键词
- 运行期间不要手动操作浏览器
- 预计运行时间：30-45 分钟

使用步骤

创建 keywords.md 文件，写入 10 个关键词
确保小红书网页已登录
发送"开始测试"
确认关键词列表后发送"确认"
等待完成（约 30-45 分钟）



# 项目：小红书自动打开链接测试（Phase 3）

## 背景
目前的限制：代码模拟点击打开小红书详情页会被检测并重定向到错误页面。
但手动右键"在新标签页中打开"是正常的。

本阶段目标：测试多种绕过检测的方法，找到一种能成功自动打开详情页的方式。

## 前置步骤：加载完整列表
在尝试打开链接之前，需要先完成：
1. 鼠标模拟向下滚动，触发页面懒加载
2. 持续滚动直到加载出至少 50 条内容（或页面不再加载新内容）
3. 提取并保存所有链接到 pending_urls.json
4. 鼠标滚动回到页面顶部
5. 开始逐条尝试打开

## 测试方案

请依次实现以下 4 种方案，每种方案单独封装成函数，方便我逐个测试。

### 方案 A：右键菜单模拟
思路：模拟真实的右键操作流程
步骤：
1. 鼠标以贝塞尔曲线轨迹移动到目标链接位置
2. 移动过程中加入微小的随机抖动（模拟人手不稳）
3. 到达目标位置后，随机等待 200-500ms
4. 触发右键点击（contextmenu 事件）
5. 等待右键菜单出现
6. 模拟键盘按下"在新标签页中打开"对应的快捷键（通常是 "T" 或直接 Enter 选中第一项）
7. 等待新标签页打开

### 方案 B：键盘快捷键模拟
思路：不用鼠标点击，用键盘操作
步骤：
1. 鼠标移动到目标链接（同样用贝塞尔曲线）
2. 单击选中该链接（普通左键单击，不是打开）
3. 按下 Cmd+Enter（Mac）或 Ctrl+Enter（Windows）在新标签页打开
4. 等待新标签页打开

### 方案 C：中键点击模拟
思路：鼠标中键点击通常会在新标签页打开链接
步骤：
1. 鼠标以贝塞尔曲线移动到目标链接
2. 触发鼠标中键点击（button: 'middle'）
3. 等待新标签页打开

### 方案 D：JavaScript 注入
思路：绕过鼠标事件，直接用 JS 打开链接
步骤：
1. 获取目标链接的 href 值
2. 通过 JavaScript 执行 window.open(href, '_blank')
3. 或者创建一个 <a> 元素，设置 href 和 target="_blank"，然后用 JS 触发 click 事件
4. 等待新标签页打开

## 贝塞尔曲线鼠标移动要求
不要直接 moveTo(x, y)，要模拟真实的人手移动轨迹：
- 起点：当前鼠标位置
- 终点：目标元素中心 + 随机偏移（±5px）
- 路径：三阶贝塞尔曲线，控制点随机生成
- 移动时间：300-800ms，分成 20-40 个步骤
- 每步之间间隔 10-30ms
- 加入 1-2px 的随机抖动

## 测试流程
每个方案测试时：
1. 只尝试打开列表中的第 1 个链接
2. 等待 3 秒，检测新标签页是否成功打开
3. 如果打开了，检测页面内容是否是正确的详情页（不是重定向后的随机页面）
4. 记录结果到 test_results.json

## 输出格式

### test_results.json
```json
{
  "test_time": "2025-01-25T15:00:00Z",
  "results": [
    {
      "method": "方案A：右键菜单模拟",
      "new_tab_opened": true,
      "correct_page": false,
      "redirected_to": "https://www.xiaohongshu.com/explore/其他页面",
      "notes": "新标签打开了，但被重定向"
    },
    {
      "method": "方案B：键盘快捷键",
      "new_tab_opened": true,
      "correct_page": true,
      "redirected_to": null,
      "notes": "成功！"
    }
  ]
}
```

## 用户交互命令

实现以下命令供我手动触发测试：

- "加载50条" - 执行滚动加载，收集链接
- "测试方案A" - 只测试右键菜单模拟
- "测试方案B" - 只测试键盘快捷键
- "测试方案C" - 只测试中键点击
- "测试方案D" - 只测试 JS 注入
- "测试全部" - 依次测试所有方案，汇总结果

## 验收标准
1. 滚动能加载出 50 条内容并提取链接
2. 4 种方案都能正确执行（不报错）
3. 测试结果准确记录到 JSON
4. 找到至少 1 种能绑过检测的方法（如果存在的话）

## 注意事项
- 每种方案测试之间间隔 5 秒，避免触发频率检测
- 如果某个方案报错，捕获错误并记录，继续测试下一个
- 贝塞尔曲线移动是关键，要尽可能像真人
- 测试时我会在旁边观察，方便判断哪一步被检测了


# 项目：小红书批量抓取器（Phase 2）

## 背景
Phase 1 已验证成功，代码可以正确读取小红书详情页内容。
现在需要提高效率，实现批量处理。

由于代码模拟点击会被小红书检测并重定向，所以仍然需要我手动打开每个详情页。
但代码可以帮我：
1. 提前收集所有待抓取的链接
2. 自动检测页面变化并抓取
3. 追踪进度

## 你的任务
在 Phase 1 的基础上，增加以下功能：

### 功能 1：从搜索结果页提取链接列表
当我打开小红书搜索结果页（已排序好）时，代码能够：
- 检测当前是搜索结果页
- 提取页面上所有可见笔记的链接（不需要点击，只读取 href）
- 我手动滚动加载更多内容后，代码能重新扫描并更新列表
- 去重后保存到 pending_urls.json

### 功能 2：自动检测并抓取
启动一个监听模式：
- 持续监测当前浏览器标签页的 URL
- 当检测到 URL 变成小红书详情页时，自动执行抓取
- 抓取成功后：
  - 数据追加到 xiaohongshu_data.json
  - 从 pending_urls.json 中移除该 URL
  - 打印进度：「✅ 已抓取 X/Y：[标题前15字]...」

### 功能 3：进度管理
- 显示待抓取数量
- 显示已抓取数量
- 如果当前页面的 URL 不在待抓取列表中，提示：「⚠️ 这个链接不在待抓取列表中，是否仍要抓取？」

## 工作流程
1. 我打开小红书搜索结果页，输入关键词，排序
2. 我运行"提取链接"命令
3. 我手动滚动页面加载更多
4. 再次运行"提取链接"命令（追加新链接）
5. 我启动"监听模式"
6. 我手动右键逐个打开详情页
7. 代码自动抓取每个打开的页面
8. 直到全部完成

## 文件结构
- pending_urls.json：待抓取的 URL 列表
- xiaohongshu_data.json：已抓取的数据（Phase 1 已有）
- scrape_progress.json：进度记录（可选）

## pending_urls.json 格式示例
```json
{
  "keyword": "失眠",
  "created_at": "2025-01-25T14:00:00Z",
  "urls": [
    "https://www.xiaohongshu.com/explore/xxxxx",
    "https://www.xiaohongshu.com/explore/yyyyy"
  ]
}
```

## 验收标准
1. 搜索结果页能提取出 20+ 个链接
2. 监听模式能自动检测页面变化
3. 我手动打开详情页后，3 秒内自动完成抓取
4. 进度显示正确
5. 不重复抓取已有数据

## 注意事项
- 提取链接时只读取 DOM，不要触发任何点击
- 监听模式要轻量，不要频繁刷新导致卡顿
- 保持 Phase 1 的所有抓取逻辑不变


# 项目：小红书详情页内容抓取器（Phase 1）

## 背景
我需要在 Antigravity 环境中抓取小红书笔记详情页的内容。由于小红书有反爬机制，代码模拟点击打开链接会被重定向到错误页面。但我手动右键打开详情页是正常的。

所以本阶段的策略是：我手动打开详情页，代码负责读取页面内容并保存。

## 你的任务
创建一个脚本，实现以下功能：

### 功能 1：读取当前详情页内容
当我手动打开一个小红书笔记详情页后，代码能够：
- 检测当前页面是否是小红书笔记详情页（URL 包含 xiaohongshu.com/explore 或 /discovery/item）
- 从页面 DOM 中提取以下信息：
  - 笔记 URL
  - 标题
  - 正文全文
  - 点赞数
  - 收藏数
  - 评论数
  - 作者昵称
  - 所有图片的 URL 列表
  - 抓取时间戳

### 功能 2：保存到本地 JSON
- 文件名格式：xiaohongshu_data.json
- 每抓取一条，追加到这个 JSON 文件中（数组格式）
- 如果文件已存在，读取后追加，不要覆盖
- 保存时检查是否重复（根据 URL 判断），重复则跳过

### 功能 3：用户交互提示
- 抓取成功后，在控制台打印：「✅ 已保存：[标题前20字]... 共 X 条」
- 如果检测到页面不是详情页，打印：「⚠️ 当前页面不是小红书笔记详情页，请手动打开一个笔记」
- 提供一个简单的命令或按钮，让我触发"抓取当前页面"

## 技术要求
- 使用 Antigravity 的浏览器控制 API
- 不要模拟点击打开新页面（会被反爬拦截）
- 只读取我已经手动打开的页面
- 选择器要健壮，小红书的 class 名可能会变，优先用语义化选择（比如根据文本内容、DOM 结构位置来定位）
- 添加适当的等待，确保页面完全加载后再抓取

## 输出文件示例
```json
[
  {
    "url": "https://www.xiaohongshu.com/explore/xxxxx",
    "title": "这是笔记标题",
    "content": "这是笔记正文内容...",
    "likes": 1234,
    "collects": 567,
    "comments": 89,
    "author": "作者昵称",
    "images": [
      "https://image1.jpg",
      "https://image2.jpg"
    ],
    "scraped_at": "2025-01-25T14:30:00Z"
  }
]
```

## 验收标准
1. 我手动打开一个小红书笔记详情页
2. 运行你的脚本或触发抓取命令
3. 控制台显示抓取成功
4. 本地 JSON 文件中出现这条数据，字段完整

## 注意事项
- 这是 Phase 1，只做单页抓取，不需要批量处理
- 不需要处理登录（我已经手动登录）
- 不需要搜索功能（我手动搜索和打开）
- 重点是稳定读取 DOM，选择器要有备选方案
```

---

## 后续 Phase 预告

等 Phase 1 跑通后，我们再做：

**Phase 2**：批量模式
- 从搜索结果页提取所有笔记 URL 列表
- 你手动逐个打开，代码自动检测并抓取
- 加入进度追踪（已抓 X/50）

**Phase 3**：尝试自动化打开
- 测试键盘快捷键方式（Ctrl+Click）
- 测试鼠标轨迹模拟
- 测试其他绕过检测的方法

**Phase 4**：多关键词 + 飞书集成

---

这是抓取中国社交媒体小红书上面的 PRD 